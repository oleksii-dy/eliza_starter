/**
 * Train Model Action - Together.ai Integration for Model Training
 * 
 * Uploads training data to Together.ai and initiates fine-tuning of DeepSeek-70B
 * for ElizaOS code generation and reasoning capabilities.
 */

import type { Action, IAgentRuntime, Memory, State, HandlerCallback, UUID } from '@elizaos/core';
import { elizaLogger } from '@elizaos/core';
import * as fs from 'fs/promises';
import * as path from 'path';
import FormData from 'form-data';
import fetch from 'node-fetch';
import { getTrainingConfig } from '../config/training-config.js';

export const trainModelAction: Action = {
  name: 'TRAIN_MODEL',
  similes: ['FINE_TUNE_MODEL', 'UPLOAD_TRAINING_DATA', 'START_TRAINING'],
  description: 'Upload training data to Together.ai and start fine-tuning DeepSeek-70B model for ElizaOS code generation',

  validate: async (runtime: IAgentRuntime, message: Memory) => {
    const text = message.content.text?.toLowerCase() || '';
    
    // Exclude negative contexts
    if (text.includes('disable') || text.includes('stop') || text.includes('cancel') || 
        text.includes('don\'t') || text.includes('no')) {
      return false;
    }
    
    // Check for training-related terms
    const hasTrainingAction = text.includes('train') || text.includes('fine-tune') || text.includes('upload');
    const hasModelReference = text.includes('model') || text.includes('together') || 
                              text.includes('deepseek') || text.includes('llama');
    
    // Check for data context
    const hasDataContext = text.includes('training') || text.includes('dataset') || text.includes('data');
    
    // Special cases:
    // 1. "upload training data" implies model training even without explicit model mention
    // 2. "train the model" implies data context even without explicit data mention
    const isUploadTrainingData = text.includes('upload') && hasDataContext;
    const isTrainModel = hasTrainingAction && hasModelReference;
    
    return (hasTrainingAction && hasModelReference && hasDataContext) ||
           isUploadTrainingData || 
           isTrainModel;
  },

  handler: async (
    runtime: IAgentRuntime,
    message: Memory,
    state?: State,
    options?: { [key: string]: unknown },
    callback?: HandlerCallback
  ) => {
    try {
      elizaLogger.info('üöÇ Starting model training process...');

      // Check for Together.ai API key
      const apiKey = runtime.getSetting('TOGETHER_API_KEY');
      if (!apiKey) {
        await callback?.({
          text: `‚ùå Together.ai API key not found. Please set TOGETHER_API_KEY in your environment.\n\nTo get an API key:\n1. Visit https://api.together.xyz/\n2. Sign up or log in\n3. Generate an API key\n4. Set TOGETHER_API_KEY in your .env file`,
          thought: 'Missing Together.ai API key required for model training',
          actions: ['TRAIN_MODEL']
        });
        return { text: 'Missing Together.ai API key' };
      }

      // Extract configuration from message
      const config = extractTrainingConfig(message);
      
      // Validate training file exists first before starting
      const trainingFilePath = path.resolve(config.trainingFile);
      try {
        await fs.access(trainingFilePath);
      } catch (error) {
        await callback?.({
          text: `‚ùå Training file not found: ${trainingFilePath}\n\nPlease run the training data generation first using the GENERATE_TRAINING_DATA action.`,
          thought: 'Training file not found, user needs to generate training data first',
          actions: ['TRAIN_MODEL']
        });
        return { text: 'Training file not found' };
      }

      // Validate JSONL format before proceeding
      const validationResult = await validateTrainingData(trainingFilePath);
      if (!validationResult.valid) {
        await callback?.({
          text: `‚ùå Training data validation failed:\n${validationResult.errors.join('\n')}\n\nPlease regenerate the training data with proper formatting.`,
          thought: 'Training data validation failed, cannot proceed with upload',
          actions: ['TRAIN_MODEL']
        });
        return { text: 'Training data validation failed' };
      }

      // File exists and is valid, now we can proceed with training
      await callback?.({
        text: `üöÇ Starting Together.ai model training...\n\nConfiguration:\n- Model: ${config.baseModel}\n- Training file: ${config.trainingFile}\n- Model suffix: ${config.suffix}\n- Learning rate: ${config.learningRate}\n- Epochs: ${config.epochs}\n\nSteps:\n1. Validate training data format\n2. Upload dataset to Together.ai\n3. Start fine-tuning job\n4. Monitor training progress\n\nThis may take several hours to complete...`,
        thought: 'Initiating Together.ai model training pipeline',
        actions: ['TRAIN_MODEL']
      });

      // Show validation progress for successful files
      await callback?.({
        text: 'üîç Validating training data format...',
        thought: 'Validating JSONL format and data quality'
      });

      await callback?.({
        text: `‚úÖ Training data validation passed!\n- ${validationResult.exampleCount} training examples\n- Average tokens: ${validationResult.averageTokens}\n- Total size: ${validationResult.totalSize}`,
        thought: 'Training data validation successful, proceeding with upload'
      });


      // Upload file to Together.ai
      await callback?.({
        text: 'üì§ Uploading training data to Together.ai...',
        thought: 'Uploading JSONL file to Together.ai servers'
      });

      const fileUploadResult = await uploadTrainingFile(apiKey, trainingFilePath);
      
      await callback?.({
        text: `‚úÖ Training data uploaded successfully!\n- File ID: ${(fileUploadResult as any).id}\n- Purpose: ${(fileUploadResult as any).purpose}\n- Size: ${Math.round((fileUploadResult as any).bytes / 1024)}KB`,
        thought: 'Training file uploaded, ready to start fine-tuning job'
      });

      // Start fine-tuning job
      await callback?.({
        text: 'üöÄ Starting fine-tuning job...',
        thought: 'Creating fine-tuning job with uploaded dataset'
      });

      const fineTuningJob = await createFineTuningJob(apiKey, {
        training_file: (fileUploadResult as any).id,
        model: config.baseModel,
        suffix: config.suffix,
        hyperparameters: {
          learning_rate: config.learningRate,
          n_epochs: config.epochs,
          batch_size: config.batchSize
        }
      });

      await callback?.({
        text: `üéØ Fine-tuning job created successfully!\n\n**Job Details:**\n- Job ID: ${(fineTuningJob as any).id}\n- Model: ${(fineTuningJob as any).model}\n- Status: ${(fineTuningJob as any).status}\n- Created: ${new Date((fineTuningJob as any).created_at * 1000).toLocaleString()}\n\n**Training Configuration:**\n- Learning Rate: ${config.learningRate}\n- Epochs: ${config.epochs}\n- Batch Size: ${config.batchSize}\n\n**Next Steps:**\n1. Monitor training progress\n2. Wait for completion (typically 2-6 hours)\n3. Test the fine-tuned model\n4. Configure auto-coder to use the new model\n\nüí° You can check progress with: "Check training status for job ${(fineTuningJob as any).id}"`,
        thought: 'Fine-tuning job started successfully, providing job details and next steps',
        actions: ['TRAIN_MODEL']
      });

      // Store job info for monitoring
      await storeTrainingJobInfo(runtime, fineTuningJob, config);

      return {
        text: `Fine-tuning job ${(fineTuningJob as any).id} started successfully`,
        data: {
          jobId: (fineTuningJob as any).id,
          fileId: (fileUploadResult as any).id,
          status: (fineTuningJob as any).status,
          config
        }
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      elizaLogger.error('‚ùå Model training failed:', error);

      await callback?.({
        text: `‚ùå Model training failed: ${errorMessage}\n\nCommon issues:\n- Invalid API key\n- Incorrect file format\n- Network connectivity\n- Together.ai service issues\n\nPlease check your configuration and try again.`,
        thought: `Model training failed: ${errorMessage}`,
        actions: ['TRAIN_MODEL']
      });

      throw error;
    }
  },

  examples: [
    [
      {
        name: 'User',
        content: {
          text: 'Train a model using the generated training data on Together.ai'
        }
      },
      {
        name: 'Assistant',
        content: {
          text: 'üöÇ Starting Together.ai model training...',
          thought: 'User wants to start model training with generated data',
          actions: ['TRAIN_MODEL']
        }
      }
    ],
    [
      {
        name: 'User',
        content: {
          text: 'Fine-tune DeepSeek-70B on my ElizaOS training dataset with learning rate 0.0001'
        }
      },
      {
        name: 'Assistant',
        content: {
          text: 'üöÇ Starting Together.ai model training with custom learning rate...',
          thought: 'User specifies custom learning rate for fine-tuning',
          actions: ['TRAIN_MODEL']
        }
      }
    ]
  ]
};

/**
 * Extract training configuration from message
 */
function extractTrainingConfig(message: Memory) {
  const text = message.content.text || '';
  
  // Get configuration-based defaults
  const config = getTrainingConfig();
  const trainingDefaults = config.getModelTrainingConfig();
  
  return {
    baseModel: extractValue(text, /model[:\s]+([^\s]+)/i, trainingDefaults.defaultBaseModel),
    trainingFile: extractValue(text, /(?:file|dataset)[:\s]+([^\s]+)/i, trainingDefaults.defaultTrainingFile),
    suffix: extractValue(text, /suffix[:\s]+([^\s]+)/i, trainingDefaults.defaultModelSuffix),
    learningRate: parseFloat(extractValue(text, /learning[_\s]?rate[:\s]+([\d.e-]+)/i, trainingDefaults.defaultLearningRate.toString())),
    epochs: parseInt(extractValue(text, /epochs?[:\s]+(\d+)/i, trainingDefaults.defaultEpochs.toString())),
    batchSize: parseInt(extractValue(text, /batch[_\s]?size[:\s]+(\d+)/i, trainingDefaults.defaultBatchSize.toString()))
  };
}

/**
 * Extract value from text using regex with fallback
 */
function extractValue(text: string, regex: RegExp, defaultValue: string): string {
  const match = text.match(regex);
  return match ? match[1] : defaultValue;
}

/**
 * Validate training data JSONL format
 */
async function validateTrainingData(filePath: string) {
  try {
    const content = await fs.readFile(filePath, 'utf-8');
    const lines = content.trim().split('\n');
    
    let totalTokens = 0;
    const errors: string[] = [];
    
    for (let i = 0; i < Math.min(lines.length, 10); i++) { // Check first 10 lines
      try {
        const data = JSON.parse(lines[i]);
        
        if (!data.messages || !Array.isArray(data.messages)) {
          errors.push(`Line ${i + 1}: Missing or invalid 'messages' array`);
        } else {
          const messages = data.messages;
          if (!messages.some((m: any) => m.role === 'user') || !messages.some((m: any) => m.role === 'assistant')) {
            errors.push(`Line ${i + 1}: Missing user or assistant message`);
          }
          
          // Estimate tokens
          const textContent = messages.map((m: any) => m.content).join(' ');
          totalTokens += Math.ceil(textContent.length / 4);
        }
      } catch (parseError) {
        errors.push(`Line ${i + 1}: Invalid JSON format`);
      }
    }
    
    const stats = await fs.stat(filePath);
    
    return {
      valid: errors.length === 0,
      errors,
      exampleCount: lines.length,
      averageTokens: Math.round(totalTokens / Math.min(lines.length, 10)),
      totalSize: `${Math.round(stats.size / 1024)}KB`
    };
  } catch (error) {
    return {
      valid: false,
      errors: [`Failed to read file: ${error instanceof Error ? error.message : String(error)}`],
      exampleCount: 0,
      averageTokens: 0,
      totalSize: '0KB'
    };
  }
}

/**
 * Upload training file to Together.ai
 */
async function uploadTrainingFile(apiKey: string, filePath: string) {
  const fileContent = await fs.readFile(filePath);
  const fileName = path.basename(filePath);
  
  // Create form data using Node.js compatible FormData
  const formData = new FormData();
  formData.append('file', fileContent, {
    filename: fileName,
    contentType: 'application/jsonl',
  });
  formData.append('purpose', 'fine-tune');
  
  const response = await fetch('https://api.together.xyz/v1/files', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      ...formData.getHeaders(),
    },
    body: formData
  });
  
  if (!response.ok) {
    const error = await response.text();
    throw new Error(`File upload failed: ${response.status} ${error}`);
  }
  
  return await response.json();
}

/**
 * Create fine-tuning job
 */
async function createFineTuningJob(apiKey: string, config: any) {
  const response = await fetch('https://api.together.xyz/v1/fine-tuning/jobs', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(config)
  });
  
  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Fine-tuning job creation failed: ${response.status} ${error}`);
  }
  
  return await response.json();
}

/**
 * Store training job info for monitoring
 */
async function storeTrainingJobInfo(runtime: IAgentRuntime, job: any, config: any) {
  try {
    // Store in memory for later retrieval
    await runtime.createMemory({
      content: {
        text: `Training job ${job.id} started with model ${job.model}`,
        metadata: {
          type: 'training_job',
          jobId: job.id,
          model: job.model,
          status: job.status,
          config,
          createdAt: job.created_at
        }
      },
      entityId: runtime.agentId,
      roomId: `training-jobs-${Date.now()}` as UUID
    }, 'facts');
  } catch (error) {
    elizaLogger.warn('Failed to store training job info:', error);
  }
}

elizaLogger.info('‚úÖ Train model action loaded');