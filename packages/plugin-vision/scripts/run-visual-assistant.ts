#!/usr/bin/env tsx
/**
 * Run the Visual Assistant with camera, screen, and microphone enabled
 * This demonstrates the full integration of vision, autonomy, and audio
 */

import { spawn } from 'child_process';
import path from 'path';
import { fileURLToPath } from 'url';
import { dirname } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

async function main() {
  console.log('ğŸ¤– Starting Visual Assistant with full sensory capabilities...');
  console.log('ğŸ“· Camera: Enabled');
  console.log('ğŸ–¥ï¸  Screen: Enabled');
  console.log('ğŸ¤ Microphone: Enabled (30-second transcription)');
  console.log('ğŸ§  Autonomy: Enabled\n');

  // Path to the visual assistant character
  const characterPath = path.join(__dirname, '../characters/visual-assistant.json');

  // Environment variables for the demo
  const env = {
    ...process.env,
    VISION_MODE: 'BOTH',
    ENABLE_FACE_RECOGNITION: 'true',
    ENABLE_OBJECT_DETECTION: 'true',
    ENABLE_POSE_DETECTION: 'true',
    ENABLE_MICROPHONE: 'true',
    TRANSCRIPTION_INTERVAL: '30000',
    AUTONOMOUS_ENABLED: 'true',
    AUTONOMOUS_INTERVAL: '10000',
  };

  // Run the agent using elizaos CLI
  const agent = spawn('elizaos', ['start', '--character', characterPath], {
    env,
    stdio: 'inherit',
    shell: true,
  });

  agent.on('error', (error) => {
    console.error('âŒ Failed to start agent:', error);
    process.exit(1);
  });

  agent.on('exit', (code) => {
    console.log(`Agent exited with code ${code}`);
    process.exit(code || 0);
  });
}

// Handle graceful shutdown
process.on('SIGINT', () => {
  console.log('\nğŸ‘‹ Shutting down Visual Assistant...');
  process.exit(0);
});

process.on('SIGTERM', () => {
  console.log('\nğŸ‘‹ Shutting down Visual Assistant...');
  process.exit(0);
});

// Run the assistant
main().catch((error) => {
  console.error('âŒ Failed to start Visual Assistant:', error);
  process.exit(1);
});
