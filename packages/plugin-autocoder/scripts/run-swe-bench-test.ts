#!/usr/bin/env bun

import { SWEBenchRunner } from '../src/swe-bench/swe-bench-runner.js';
import * as fs from 'fs/promises';
import * as path from 'path';

async function runSWEBenchTest() {
  console.log('üöÄ Starting SWE-bench evaluation...\n');

  // Create mock runtime with API key
  const mockRuntime = {
    getSetting: (key: string) => {
      if (key === 'ANTHROPIC_API_KEY') {
        return process.env.ANTHROPIC_API_KEY;
      }
      return undefined;
    },
    getService: (serviceName: string) => {
      // Mock getService to return null for optional services
      return null;
    },
    useModel: async (modelType: string, params: any) => {
      // Mock useModel for AI operations
      return 'Mock AI response';
    },
    agentId: 'swe-bench-test',
    character: {
      name: 'SWEBenchAgent',
      bio: ['Agent for SWE-bench evaluation'],
      knowledge: [],
      messageExamples: [],
      postExamples: [],
      topics: [],
      plugins: [],
    },
    logger: {
      info: console.log,
      warn: console.warn,
      error: console.error,
      debug: console.debug,
    },
  } as any;

  // Check API key
  if (!process.env.ANTHROPIC_API_KEY) {
    console.error('‚ùå Error: ANTHROPIC_API_KEY environment variable not set');
    console.log('\nPlease set your Anthropic API key:');
    console.log('export ANTHROPIC_API_KEY="your-key-here"');
    process.exit(1);
  }

  // Create runner
  const runner = new SWEBenchRunner(mockRuntime, {
    docker_enabled: false,
    max_parallel_instances: 1,
    cleanup_after_run: true,
  });

  try {
    // Initialize
    console.log('üì¶ Initializing SWE-bench runner...');
    await runner.initialize();

    // Get dataset stats first
    console.log('\nüìä Loading dataset statistics...');
    const stats = await runner.getDatasetStats();
    console.log(`Total instances: ${stats.total}`);
    console.log(
      `TypeScript/JavaScript: ${(stats.byLanguage['TypeScript'] || 0) + (stats.byLanguage['JavaScript'] || 0)}`
    );

    // Run on a small set of instances
    const maxInstances = parseInt(process.env.SWE_BENCH_MAX || '3');
    console.log(`\nüîß Running evaluation on ${maxInstances} instances...\n`);

    const report = await runner.runBenchmark({
      max_instances: maxInstances,
      language_filter: ['TypeScript', 'JavaScript'],
      save_artifacts: true,
      skip_evaluation: true, // Skip Python evaluation for now
      complexity_filter: ['low'], // Start with easier instances
    });

    // Save report
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const reviewDir = path.join(process.cwd(), 'swe-bench-human-review', `run-${timestamp}`);
    await fs.mkdir(reviewDir, { recursive: true });

    // Save main report
    await fs.writeFile(path.join(reviewDir, 'report.json'), JSON.stringify(report, null, 2));

    // Save summary
    const summary = {
      timestamp: new Date().toISOString(),
      duration_minutes: (report.duration / 1000 / 60).toFixed(2),
      total_instances: report.results.total_instances,
      resolved: report.results.resolved_instances,
      resolution_rate: `${(report.results.resolution_rate * 100).toFixed(1)}%`,
      compilation_success_rate: `${(report.results.compilation_success_rate * 100).toFixed(1)}%`,
      test_pass_rate: `${(report.results.test_pass_rate * 100).toFixed(1)}%`,
      avg_execution_time_seconds: (report.results.summary.avg_execution_time / 1000).toFixed(1),
      total_cost: `$${report.results.summary.total_cost.toFixed(2)}`,
      instances: report.results.per_instance_results.map((r) => ({
        id: r.instance_id,
        resolved: r.resolved,
        compilation: r.compilation_success,
        tests_passed: r.tests_passed,
        time_seconds: (r.execution_time / 1000).toFixed(1),
        error: r.error,
      })),
    };

    await fs.writeFile(path.join(reviewDir, 'summary.json'), JSON.stringify(summary, null, 2));

    // Create markdown report
    let markdown = `# SWE-bench Evaluation Report

**Date**: ${new Date().toISOString()}
**Duration**: ${summary.duration_minutes} minutes

## Summary

- **Total Instances**: ${summary.total_instances}
- **Resolved**: ${summary.resolved} (${summary.resolution_rate})
- **Compilation Success**: ${summary.compilation_success_rate}
- **Test Pass Rate**: ${summary.test_pass_rate}
- **Average Time**: ${summary.avg_execution_time_seconds}s per instance
- **Total Cost**: ${summary.total_cost}

## Instance Results

| Instance | Resolved | Compilation | Tests | Time (s) | Error |
|----------|----------|-------------|-------|----------|-------|
`;

    for (const inst of summary.instances) {
      markdown += `| ${inst.id} | ${inst.resolved ? '‚úÖ' : '‚ùå'} | ${inst.compilation ? '‚úÖ' : '‚ùå'} | ${inst.tests_passed ? '‚úÖ' : '‚ùå'} | ${inst.time_seconds} | ${inst.error || '-'} |\n`;
    }

    markdown += `\n## Artifacts

Patches and logs saved in: ${report.artifacts_dir || 'Not available'}
`;

    await fs.writeFile(path.join(reviewDir, 'report.md'), markdown);

    // Copy artifacts if available
    if (report.artifacts_dir) {
      const artifactsDir = path.join(reviewDir, 'artifacts');
      await fs.mkdir(artifactsDir, { recursive: true });

      try {
        await fs.cp(report.artifacts_dir, artifactsDir, { recursive: true });
      } catch (error) {
        console.log('Note: Could not copy artifacts:', error.message);
      }
    }

    console.log('\n‚úÖ Evaluation complete!');
    console.log(`\nüìÅ Results saved to: ${reviewDir}`);
    console.log('\nSummary:');
    console.log(`- Resolution Rate: ${summary.resolution_rate}`);
    console.log(`- Compilation Success: ${summary.compilation_success_rate}`);
    console.log(`- Total Cost: ${summary.total_cost}`);
  } catch (error) {
    console.error('\n‚ùå Error running SWE-bench:', error);

    // Save error report
    const errorReport = {
      timestamp: new Date().toISOString(),
      error: error.message,
      stack: error.stack,
    };

    await fs.writeFile(
      path.join(process.cwd(), 'swe-bench-human-review', 'error-report.json'),
      JSON.stringify(errorReport, null, 2)
    );
  }
}

// Run the test
runSWEBenchTest().catch(console.error);
